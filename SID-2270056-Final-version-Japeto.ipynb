{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eec1d2d-565e-45df-bcf6-780beaac0c49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\oriol\\anaconda3\\lib\\site-packages (4.50.0)\n",
      "Requirement already satisfied: torch in c:\\users\\oriol\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\oriol\\anaconda3\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\oriol\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\oriol\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\oriol\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\oriol\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\oriol\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch datasets scikit-learn pandas openpyxl imbalanced-learn --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9125fc25-8ff4-40f6-a946-1616adfd715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b8d04dc-d792-48f0-b563-8ea48bc4adb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category distribution before oversampling:\n",
      "categories\n",
      "General conversation    93\n",
      "Other                   82\n",
      "Japeto Chat             71\n",
      "Services                68\n",
      "Compliance              51\n",
      "About Japeto            48\n",
      "Project management      47\n",
      "Paige                   36\n",
      "Apps                    28\n",
      "AI services             25\n",
      "Billing                 23\n",
      "Contact                 23\n",
      "Technical stack         21\n",
      "Support                 20\n",
      "Partnerships            19\n",
      "Feedback                19\n",
      "Pat                     18\n",
      "Recruitment             11\n",
      "Managed hosting          3\n",
      "Websites                 3\n",
      "Name: count, dtype: int64\n",
      "Data preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "file_path = \"chatbot_dataset.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Keep only AI-generated responses\n",
    "df_ai = df[df[\"response_source\"] == \"Generative AI\"].copy()\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower().strip()\n",
    "        text = re.sub(r\"[^\\w\\s.,!?]\", \"\", text)  # Retain important punctuation\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "df_ai[\"user_message\"] = df_ai[\"user_message\"].apply(clean_text)\n",
    "df_ai[\"chatbot_response\"] = df_ai[\"chatbot_response\"].apply(clean_text)\n",
    "df_ai[\"combined_text\"] = df_ai[\"user_message\"] + \" \" + df_ai[\"chatbot_response\"]\n",
    "\n",
    "# Encode categories\n",
    "label_encoder = LabelEncoder()\n",
    "df_ai[\"category_encoded\"] = label_encoder.fit_transform(df_ai[\"categories\"])\n",
    "\n",
    "# Check class distribution before oversampling\n",
    "print(\"Category distribution before oversampling:\")\n",
    "print(df_ai[\"categories\"].value_counts())\n",
    "\n",
    "# Apply RandomOverSampler **before** splitting\n",
    "ros = RandomOverSampler(random_state=SEED)\n",
    "X_resampled, y_resampled = ros.fit_resample(df_ai[[\"combined_text\"]], df_ai[\"category_encoded\"])\n",
    "\n",
    "# Convert DataFrame back to list for tokenization\n",
    "X_resampled = X_resampled[\"combined_text\"].tolist()\n",
    "\n",
    "# Split the resampled data into training (80%) and testing (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, \n",
    "                                                    test_size=0.2, random_state=SEED, stratify=y_resampled)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Tokenize datasets efficiently\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "print(\"Data preprocessing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8f5f4ae-1fcb-4bae-ab9a-181683cb7d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully converted to PyTorch format!\n"
     ]
    }
   ],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self, encodings, labels, device=\"cpu\"):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.device = device  # Store device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]).to(self.device) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx]).to(self.device)\n",
    "        return item\n",
    "\n",
    "# Convert to PyTorch Dataset (ensure labels are correct)\n",
    "train_dataset = ChatbotDataset(train_encodings, y_train.tolist(), device)\n",
    "test_dataset = ChatbotDataset(test_encodings, y_test.tolist(), device)\n",
    "\n",
    "print(\"Dataset successfully converted to PyTorch format!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a35e10-ab02-463a-876f-cd97d6857260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Oriol\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [372/372 3:22:08, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.662126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.811693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.489338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.411133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load DistilBERT model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(label_encoder.classes_)).to(device)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,  # Increased batch size\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,  # More stable training\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Create Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Train the model (Only run ONCE)\n",
    "trainer.train()\n",
    "\n",
    "# Save trained model\n",
    "trainer.save_model(\"./trained_model_v2\")\n",
    "print(\"Model training complete and saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d416bef-e3ac-44bf-8f6e-8a181668cb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy (DistilBERT + Optimized Data): 91.67%\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "         AI services       0.86      1.00      0.92        18\n",
      "        About Japeto       0.94      0.94      0.94        18\n",
      "                Apps       1.00      1.00      1.00        19\n",
      "             Billing       1.00      1.00      1.00        18\n",
      "          Compliance       0.86      0.95      0.90        19\n",
      "             Contact       1.00      1.00      1.00        18\n",
      "            Feedback       0.86      1.00      0.93        19\n",
      "General conversation       0.94      0.79      0.86        19\n",
      "         Japeto Chat       1.00      0.89      0.94        18\n",
      "     Managed hosting       1.00      1.00      1.00        19\n",
      "               Other       0.82      0.47      0.60        19\n",
      "               Paige       0.70      0.78      0.74        18\n",
      "        Partnerships       0.86      1.00      0.93        19\n",
      "                 Pat       1.00      1.00      1.00        19\n",
      "  Project management       0.85      0.89      0.87        19\n",
      "         Recruitment       1.00      1.00      1.00        18\n",
      "            Services       0.76      0.68      0.72        19\n",
      "             Support       1.00      1.00      1.00        18\n",
      "     Technical stack       0.90      0.95      0.92        19\n",
      "            Websites       1.00      1.00      1.00        19\n",
      "\n",
      "            accuracy                           0.92       372\n",
      "           macro avg       0.92      0.92      0.91       372\n",
      "        weighted avg       0.92      0.92      0.91       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Set the correct model path\n",
    "model_path = \"./trained_model_v2\"\n",
    "\n",
    "\n",
    "\n",
    "# Ensure model exists\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(\"Trained model not found! Make sure you trained and saved it correctly.\")\n",
    "\n",
    "# Load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path).to(device)\n",
    "\n",
    "# Recreate TrainingArguments for evaluation\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_eval\",\n",
    "    eval_strategy=\"epoch\",  # future-safe version of evaluation_strategy\n",
    "    per_device_eval_batch_size=16,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Recreate Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=test_dataset,  # test_dataset must be defined earlier\n",
    ")\n",
    "\n",
    "# Run evaluation\n",
    "print(\"Running evaluation...\")\n",
    "preds = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Generate classification report\n",
    "classification_rep = classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    labels=np.arange(len(label_encoder.classes_)),\n",
    "    target_names=label_encoder.classes_,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nModel Accuracy (DistilBERT + Optimized Data): {accuracy * 100:.2f}%\\n\")\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef752db1-2e5b-4fb4-9020-5078392469d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
